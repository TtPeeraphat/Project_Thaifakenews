import streamlit as st
import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
import pickle
import os
from torch_geometric.data import Data
from torch_geometric.nn import GCNConv
from sklearn.neighbors import NearestNeighbors
from sklearn.preprocessing import normalize
from sentence_transformers import SentenceTransformer
from collections import Counter

# ==========================================
# 1. Config & Device
# ==========================================
st.set_page_config(page_title="Fake News Detector", page_icon="üïµÔ∏è")
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

# ==========================================
# 2. Define Model Architecture (‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏ï‡∏≠‡∏ô‡πÄ‡∏ó‡∏£‡∏ô‡πÄ‡∏õ‡πä‡∏∞‡πÜ)
# ==========================================
class GCNNet(nn.Module):
    def __init__(self, num_node_features, num_classes, hidden_channels=256, dropout_rate=0.4):
        super().__init__()
        self.conv1 = GCNConv(num_node_features, hidden_channels)
        self.conv2 = GCNConv(hidden_channels, num_classes)
        self.dropout_rate = dropout_rate

    def forward(self, data):
        x, edge_index = data.x, data.edge_index
        edge_weight = getattr(data, 'edge_attr', None)
        
        x = self.conv1(x, edge_index, edge_weight=edge_weight)
        x = F.relu(x)
        x = F.dropout(x, p=self.dropout_rate, training=self.training)
        x = self.conv2(x, edge_index, edge_weight=edge_weight)
        return x

# ==========================================
# 3. Define Prediction Function (‡∏ï‡∏±‡∏ß‡∏ó‡∏µ‡πà Error ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏Å‡∏µ‡πâ)
# ==========================================
def predict_news(content, topn, x_np, label2id, id2label, y_cat_np, id2cat, device, nbrs, model_gnn, embed_fn):  
    # 1) Embedding
    emb_batch = embed_fn([content])
    content_emb = emb_batch[0]
    emb = normalize(content_emb.reshape(1, -1), axis=1, norm='l2')[0]

    # 2) KNN Search
    dists, idxs = nbrs.kneighbors(emb.reshape(1, -1), n_neighbors=topn)
    idxs = idxs[0]
    
    # Predict Category
    pred_category = "‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏"
    neighbor_cats = []
    if y_cat_np is not None and id2cat is not None:
        neighbor_cat_ids = y_cat_np[idxs]
        neighbor_cats = [id2cat[cid] for cid in neighbor_cat_ids]
        most_common = Counter(neighbor_cats).most_common(1)
        if most_common:
            pred_category = most_common[0][0]

    # 3) Build Graph
    X_new = np.vstack([emb, x_np[idxs]])
    center = 0
    neighbors = np.arange(1, topn + 1)
    
    edge_index_new = np.concatenate([
        np.stack([np.full(topn, center), neighbors]),
        np.stack([neighbors, np.full(topn, center)])
    ], axis=1)
    
    edge_weight_new = np.concatenate([1 - dists[0], 1 - dists[0]])

    data_new = Data(
        x=torch.tensor(X_new, dtype=torch.float, device=device),
        edge_index=torch.tensor(edge_index_new, dtype=torch.long, device=device),
        edge_attr=torch.tensor(edge_weight_new, dtype=torch.float, device=device),
    )

    # 4) Predict Real/Fake
    model_gnn.eval()
    with torch.no_grad():
        logits = model_gnn(data_new)
        probas = torch.softmax(logits, dim=1)[0].cpu().numpy()
        pred_id = int(np.argmax(probas)) 
        label_pred = id2label[pred_id]

    return {
        'label': label_pred,           
        'probability': float(probas[pred_id]), 
        'proba_all': probas.tolist(),  
        'category': pred_category,     
        'neighbor_cats': neighbor_cats, # üî• ‡∏ï‡∏±‡∏ß‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ
        'pred_id': pred_id             
    }

# ==========================================
# 4. Load Resources (Cache ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡πÇ‡∏´‡∏•‡∏î‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß)
# ==========================================
@st.cache_resource
def load_resources():
    print("üîÑ Loading resources...")
    
    # 1. Load Artifacts
    if not os.path.exists('artifacts.pkl'):
        st.error("‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå artifacts.pkl")
        return None
        
    with open('artifacts.pkl', 'rb') as f:
        artifacts = pickle.load(f)

    # 2. Build KNN Engine (‡∏™‡∏î‡πÜ ‡∏´‡∏ô‡πâ‡∏≤‡πÄ‡∏ß‡πá‡∏ö)
    # ‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏: n_neighbors ‡∏ï‡πâ‡∏≠‡∏á‡πÑ‡∏°‡πà‡πÄ‡∏Å‡∏¥‡∏ô‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏°‡∏µ
    k = min(10, len(artifacts['x_np']))
    nbrs_engine = NearestNeighbors(n_neighbors=k, metric='cosine').fit(artifacts['x_np'])

    # 3. Load SentenceBERT
    bert_model = SentenceTransformer('paraphrase-multilingual-mpnet-base-v2')
    embed_fn = lambda x: bert_model.encode(x)

    # 4. Load GCN Model
    model = GCNNet(num_node_features=artifacts['x_np'].shape[1], num_classes=2).to(device)
    
    if os.path.exists('best_model.pth'):
        model.load_state_dict(torch.load('best_model.pth', map_location=device))
        print("‚úÖ Model loaded.")
    else:
        st.warning("‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå best_model.pth (‡∏à‡∏∞‡πÉ‡∏ä‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏õ‡∏•‡πà‡∏≤‡πÜ)")

    return artifacts, nbrs_engine, embed_fn, model

# ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡∏≠‡∏á
resources = load_resources()

if resources:
    artifacts, nbrs_engine, embed_fn, model = resources
    x_bal = artifacts['x_np']
    y_cat_bal = artifacts.get('y_cat_np') # ‡πÉ‡∏ä‡πâ .get ‡∏Å‡∏±‡∏ô error
    id2label = artifacts['id2label']
    id2cat = artifacts['id2cat']
else:
    st.stop() # ‡∏´‡∏¢‡∏∏‡∏î‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏ñ‡πâ‡∏≤‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡∏≠‡∏á‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ

# ==========================================
# 5. UI (‡∏™‡πà‡∏ß‡∏ô‡∏´‡∏ô‡πâ‡∏≤‡πÄ‡∏ß‡πá‡∏ö)
# ==========================================
st.title("üïµÔ∏è Fake News Detection System")
st.write("‡∏£‡∏∞‡∏ö‡∏ö‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ç‡πà‡∏≤‡∏ß‡∏õ‡∏•‡∏≠‡∏°‡∏î‡πâ‡∏ß‡∏¢ GNN + BERT")

news_text = st.text_area("‡∏ß‡∏≤‡∏á‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏Ç‡πà‡∏≤‡∏ß‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö:", height=150)

if st.button("‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á"):
    if not news_text:
        st.warning("‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡πÉ‡∏™‡πà‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏Ç‡πà‡∏≤‡∏ß‡∏Å‡πà‡∏≠‡∏ô‡∏Ñ‡∏£‡∏±‡∏ö")
    else:
        with st.spinner('AI ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå...'):
            try:
                # ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô predict_news ‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏∞‡∏Å‡∏≤‡∏®‡πÑ‡∏ß‡πâ‡∏î‡πâ‡∏≤‡∏ô‡∏ö‡∏ô
                result = predict_news(
                    content=news_text,
                    topn=10,
                    x_np=x_bal,
                    label2id=None,
                    id2label=id2label,
                    y_cat_np=y_cat_bal,
                    id2cat=id2cat,
                    device=device,
                    nbrs=nbrs_engine,
                    model_gnn=model,
                    embed_fn=embed_fn
                )
                
                # ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•
                st.divider()
                col1, col2 = st.columns(2)
                
                with col1:
                    if result['label'] == '‡∏Ç‡πà‡∏≤‡∏ß‡∏à‡∏£‡∏¥‡∏á': 
                        st.success(f"## ‚úÖ {result['label']}")
                    else:
                        st.error(f"## üö® {result['label']}")
                    
                    st.metric("‡∏Ñ‡∏ß‡∏≤‡∏°‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à (Confidence)", f"{result['probability']*100:.2f}%")
                
                with col2:
                    st.info(f"**‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà‡∏´‡∏•‡∏±‡∏Å:** {result['category']}")
                    st.write("**üïµÔ∏è ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ô‡∏ö‡πâ‡∏≤‡∏ô 10 ‡∏≠‡∏±‡∏ô‡∏î‡∏±‡∏ö‡πÅ‡∏£‡∏Å:**")
                    
                    neighbor_cats = result.get('neighbor_cats', [])
                    if neighbor_cats:
                        for i, cat in enumerate(neighbor_cats):
                            st.markdown(f"**{i+1}.** <span style='color:gray'>(‡∏´‡∏°‡∏ß‡∏î: {cat})</span>", unsafe_allow_html=True)
                    else:
                        st.write("- ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•")

                # Debug
                with st.expander("üîç Debug Information"):
                    st.write(f"Predicted ID: {result.get('pred_id')}")
                    st.write("Neighbors Categories:", neighbor_cats)
                    from collections import Counter
                    if neighbor_cats:
                        st.write("Count:", Counter(neighbor_cats))

            except Exception as e:
                st.error(f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: {e}")
                st.write(e)