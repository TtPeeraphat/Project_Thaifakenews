{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f3c3c11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ad5382",
   "metadata": {},
   "source": [
    "pip install --quiet transformers\n",
    "pip install torch\n",
    "pip install pandas\n",
    "pip install pythainlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb7bab50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# โหลดไฟล์ CSV (กรณีชื่อคอลัมน์ 'label')\n",
    "df = pd.read_csv('dataset_truefakenews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7de19749",
   "metadata": {},
   "outputs": [],
   "source": [
    "# กำหนด mapping dictionary\n",
    "label_map = {\n",
    "    'ข่าวจริง': 'true',\n",
    "    'คลังความรู้': 'true',\n",
    "    'ข่าวปลอม': 'fake',\n",
    "    'อาชญากรออนไลน์': 'fake',\n",
    "    'ข่าวบิดเบือน': 'fake',\n",
    "    'ข่าวอื่นๆ': None  # หรือจะลบออกเลย\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03853ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  date                                         link  \\\n",
      "0  23/07/2568 10:00:39  https://www.antifakenewscenter.com/?p=74610   \n",
      "1  23/07/2568 09:00:20  https://www.antifakenewscenter.com/?p=74581   \n",
      "2  23/07/2568 08:00:51  https://www.antifakenewscenter.com/?p=74577   \n",
      "3  23/07/2568 07:00:51  https://www.antifakenewscenter.com/?p=74573   \n",
      "4  23/07/2568 06:30:23  https://www.antifakenewscenter.com/?p=74569   \n",
      "\n",
      "                                               title  \\\n",
      "0  กระทรวงกลาโหม จัดประชุม GBC เซ็นสัญญายอมให้ทหา...   \n",
      "1  OR ชวนร่วมเป็นเจ้าของกิจการ ลงทุนหุ้น IPO เริ่...   \n",
      "2  กระทรวงยุติธรรม เปิดเพจเฟซบุ๊กชื่อ Technology ...   \n",
      "3  หุ้น OKJ เปิดเทรดวันแรก ราคาเปิดพอร์ตเริ่มต้น ...   \n",
      "4  กรุงไทย เปิดให้จองสิทธิ์ยืมเงิน 100,000 บาท ลง...   \n",
      "\n",
      "                                             content  \\\n",
      "0  ก่อนแชร์ต่อ อย่าลืมเช็ก ตามที่กองบัญชาการกองทั...   \n",
      "1  จากที่มีการโฆษณาระบุเปิดให้ลงทุนหุ้น IPO ข้างต...   \n",
      "2  ระวังเพจปลอมแอบอ้างหน่วยงาน เพจเฟซบุ๊กชื่อ Tec...   \n",
      "3  เช็กข้อมูลให้ชัวร์ก่อนติดตาม เพจ “OH KAD” เป็น...   \n",
      "4  การปล่อยสินเชื่อ บนบัญชี TikTok ชื่อ ktb.thai ...   \n",
      "\n",
      "                                              author         label  \\\n",
      "0                 กองบัญชาการกองทัพไทย กระทรวงกลาโหม  ข่าวบิดเบือน   \n",
      "1  บริษัท ปตท. น้ำมันและการค้าปลีก จำกัด (มหาชน) ...      ข่าวปลอม   \n",
      "2        สำนักงานปลัดกระทรวงยุติธรรม กระทรวงยุติธรรม      ข่าวปลอม   \n",
      "3                        ตลาดหลักทรัพย์แห่งประเทศไทย      ข่าวปลอม   \n",
      "4                       ธนาคารกรุงไทย กระทรวงการคลัง      ข่าวปลอม   \n",
      "\n",
      "               category label_binary  \n",
      "0  ความสงบและความมั่นคง         fake  \n",
      "1          การเงิน-หุ้น         fake  \n",
      "2  นโยบายรัฐบาล-ข่าวสาร         fake  \n",
      "3          การเงิน-หุ้น         fake  \n",
      "4          การเงิน-หุ้น         fake  \n"
     ]
    }
   ],
   "source": [
    "# สร้างคอลัมน์ใหม่ 'label_binary' เป็น binary label จาก mapping\n",
    "#df['label_binary'] = df['label'].map(label_map)\n",
    "\n",
    "# ลบแถวที่เป็น None (ข่าวอื่นๆ)\n",
    "#df = df.dropna(subset=['label_binary'])\n",
    "\n",
    "# ถ้าต้องการ save เป็น CSV ใหม่\n",
    "#df.to_csv('news_dataset_truefakenews.csv', index=False)\n",
    "\n",
    "# ดูผลลัพธ์\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "30430b5a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "\nAutoModelForSequenceClassification requires the PyTorch library but it was not found in your environment. Check out the instructions on the\ninstallation page: https://pytorch.org/get-started/locally/ and follow the ones that match your environment.\nPlease note that you may need to restart your runtime after installation.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m model_name = \u001b[33m\"\u001b[39m\u001b[33mmonsoon-nlp/bert-base-thai\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      3\u001b[39m tokenizer = AutoTokenizer.from_pretrained(model_name)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m model = \u001b[43mAutoModelForSequenceClassification\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m(model_name, num_labels=\u001b[32m2\u001b[39m)\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Add device configuration and move model to device\u001b[39;00m\n\u001b[32m      7\u001b[39m device = torch.device(\u001b[33m'\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch.cuda.is_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tt_pe\\Documents\\GitHub\\Project_Thaifakenews\\.venv\\Lib\\site-packages\\transformers\\utils\\import_utils.py:2116\u001b[39m, in \u001b[36mDummyObject.__getattribute__\u001b[39m\u001b[34m(cls, key)\u001b[39m\n\u001b[32m   2114\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (key.startswith(\u001b[33m\"\u001b[39m\u001b[33m_\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m key != \u001b[33m\"\u001b[39m\u001b[33m_from_config\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m key == \u001b[33m\"\u001b[39m\u001b[33mis_dummy\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m key == \u001b[33m\"\u001b[39m\u001b[33mmro\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m key == \u001b[33m\"\u001b[39m\u001b[33mcall\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   2115\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().\u001b[34m__getattribute__\u001b[39m(key)\n\u001b[32m-> \u001b[39m\u001b[32m2116\u001b[39m \u001b[43mrequires_backends\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_backends\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tt_pe\\Documents\\GitHub\\Project_Thaifakenews\\.venv\\Lib\\site-packages\\transformers\\utils\\import_utils.py:2102\u001b[39m, in \u001b[36mrequires_backends\u001b[39m\u001b[34m(obj, backends)\u001b[39m\n\u001b[32m   2099\u001b[39m         failed.append(msg.format(name))\n\u001b[32m   2101\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m failed:\n\u001b[32m-> \u001b[39m\u001b[32m2102\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m.join(failed))\n",
      "\u001b[31mImportError\u001b[39m: \nAutoModelForSequenceClassification requires the PyTorch library but it was not found in your environment. Check out the instructions on the\ninstallation page: https://pytorch.org/get-started/locally/ and follow the ones that match your environment.\nPlease note that you may need to restart your runtime after installation.\n"
     ]
    }
   ],
   "source": [
    "# Load Thai BERT model and tokenizer from monsoon-nlp\n",
    "model_name = \"monsoon-nlp/bert-base-thai\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
    "\n",
    "# Add device configuration and move model to device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "model = model.to(device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
